{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from a_star import AStarTime, AStarSearch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "def save_mat(path, to_save):\n",
    "    '''\n",
    "    Save data to mat file\n",
    "    Args:\n",
    "        path: path to save mat file\n",
    "        to_save: data to save in the mat\n",
    "    '''\n",
    "    scio.savemat(path, to_save) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Replanning Baseline Codes\n",
    "Version: 1.0\n",
    "\n",
    "Author: Weizhe Lin @ Feb 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# next_loc, agent_path, num_replan = follow_path(env_img, agent_path, end, num_replan)\n",
    "\n",
    "def follow_path(img, agent_path, end, num_replan):\n",
    "    '''\n",
    "    AStar replanning function. Input one agent's plan and ask the agent to move one step. \n",
    "    If the next step is prohibited, replanning is executed to obtain new path using AStar, taking other\n",
    "    agents as obstacles.\n",
    "    Args:\n",
    "        img: map\n",
    "        agent_path: current agent path\n",
    "        end: goal position\n",
    "        num_replan: number of replanning, to be accumulated during execution\n",
    "    Returns:\n",
    "        (loc_x, loc_y): new locations of the agent\n",
    "        agent_path: planned agent path, might have been replanned. Otherwise follow the original plan\n",
    "        num_replan: accumulated number of replanning, +1 if replanning is executed\n",
    "    '''\n",
    "    old_path = agent_path.copy()\n",
    "    loc_x = np.where(img==2)[0][0]\n",
    "    loc_y = np.where(img==2)[1][0]\n",
    "    if len(old_path) == 0:\n",
    "        # no path to be computed\n",
    "        next_x, next_y = loc_x, loc_y\n",
    "#     end_x, end_y = agent_path[-1][0], agent_path[-1][1]\n",
    "#     end = (end_x, end_y)\n",
    "    else:\n",
    "        next_x, next_y = agent_path[0][0], agent_path[0][1]\n",
    "    if img[next_x, next_y] == -1 or img[next_x, next_y] == 0:\n",
    "        if (next_x, next_y) == end:\n",
    "            print('reach target')\n",
    "            return (next_x, next_y), agent_path, num_replan\n",
    "        else: \n",
    "            return (next_x, next_y), agent_path[1:], num_replan\n",
    "    else:\n",
    "        agent_path = AStarSearch(img, (loc_x, loc_y), end)\n",
    "        num_replan += 1\n",
    "        if len(agent_path) == 0:\n",
    "#             print('wait')\n",
    "            return (loc_x, loc_y), old_path, num_replan\n",
    "#         print('num_replan:', num_replan)\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                if img[i,j] == -1:\n",
    "                    img[i,j] = 0\n",
    "#         img = plot_path(img, agent_path)\n",
    "        return (loc_x, loc_y), agent_path[1:], num_replan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map20x20_density_p1/10_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "ecbs_data = []\n",
    "for root, dirs, files in os.walk(os.path.join(DATA_FOLDER, 'input')):\n",
    "    for f in files:\n",
    "        print(len(data), end='\\r')\n",
    "        if len(data) >= DATA_NUM:\n",
    "            break\n",
    "        IDMAP = f.split('IDMap')[1].split('_')[0]\n",
    "        IDCase = f.split('IDCase')[1].split('.yaml')[0]\n",
    "        IDMAP = int(IDMAP)\n",
    "        IDCase = int(IDCase)\n",
    "        if IDMAP >= DATA_RANGE[0] and IDMAP <= DATA_RANGE[1]:\n",
    "            with open(os.path.join(root, f),'r',encoding='utf-8') as fs:\n",
    "                cont = fs.read()\n",
    "                x = yaml.load(cont)\n",
    "                \n",
    "#             print(IDMAP, IDCase)\n",
    "            \n",
    "            output_name = f.replace('input', 'output').split('.yaml')[0] + '_ECBS.yaml'\n",
    "            output_path = os.path.join(DATA_FOLDER, 'output_ECBS', output_name)\n",
    "            if os.path.exists(output_path):\n",
    "                with open(output_path ,'r',encoding='utf-8') as fs:\n",
    "                    cont = fs.read()\n",
    "                    y = yaml.load(cont)\n",
    "#                     print(output_name)\n",
    "                data.append(x)\n",
    "                ecbs_data.append(y)\n",
    "\n",
    "print(len(data))\n",
    "print(len(ecbs_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowtime_increase_list = []\n",
    "# time_cost_list = []\n",
    "# all_success_count = []\n",
    "# individual_success_count = []\n",
    "# dim_num = None\n",
    "\n",
    "# for input_data, output_data in tqdm(zip(data, ecbs_data), total=len(data)):\n",
    "#     success_count = []\n",
    "#     start_time = time.time()\n",
    "#     expert_makespan = output_data['statistics']['makespan']\n",
    "#     expert_cost = output_data['statistics']['cost']\n",
    "    \n",
    "# #     print('===')\n",
    "# #     print(input_data)\n",
    "# #     print(output_data)\n",
    "#     env = np.zeros(input_data['map']['dimensions'])\n",
    "#     for obs in input_data['map']['obstacles']:\n",
    "#         env[obs[0], obs[1]] = 1\n",
    "#     if not dim_num:\n",
    "#         dim_num = [input_data['map']['dimensions'][0], len(input_data['agents'])]\n",
    "#     all_start = []\n",
    "#     all_end = []\n",
    "    \n",
    "#     agent_paths = []\n",
    "#     agent_positions = []\n",
    "#     for agent_data in input_data['agents']:\n",
    "#         start = agent_data['start']\n",
    "#         end = agent_data['goal']\n",
    "#         all_start.append(start)\n",
    "#         all_end.append(end)\n",
    "#         agent_positions.append(start)\n",
    "    \n",
    "#     # init\n",
    "    \n",
    "#     for i in range(len(input_data['agents'])):\n",
    "#         img = env.copy()\n",
    "# #         print('agent', i, (agent_positions[i][0], agent_positions[i][1]), all_end[i])\n",
    "#         for other_agent_pos in [agent_pos for agent_index, \n",
    "#                                 agent_pos in enumerate(agent_positions) if agent_index!=i]:\n",
    "#             img[other_agent_pos[0], other_agent_pos[1]] = 1\n",
    "# #             print('added as obs', other_agent_pos)\n",
    "#         agent_path = AStarSearch(img, (agent_positions[i][0], agent_positions[i][1]), all_end[i])\n",
    "#         agent_paths.append(agent_path[1:])\n",
    "    \n",
    "#     num_replan = [0] * len(input_data['agents'])\n",
    "#     flag_done = [0] * len(input_data['agents'])\n",
    "#     current_step=1\n",
    "#     while current_step < expert_makespan*3:\n",
    "# #         print('======roound', current_step)\n",
    "#         # start moving\n",
    "#         for i in range(len(input_data['agents'])):\n",
    "#             if flag_done[i] != 0:\n",
    "# #                 print('ignore agent', i, agent_positions[i], 'num_replan', num_replan[i])\n",
    "#                 continue\n",
    "#             img = env.copy()\n",
    "#             for other_agent_pos in [agent_pos for agent_index, \n",
    "#                                     agent_pos in enumerate(agent_positions) if agent_index!=i]:\n",
    "#                 img[other_agent_pos[0], other_agent_pos[1]] = 1\n",
    "#             img[agent_positions[i][0], agent_positions[i][1]] = 2\n",
    "# #             img[all_end[i][0], all_end[i][1]] = -1\n",
    "# #             print('old agent path', agent_paths[i])\n",
    "#             next_loc, agent_path, num_replan[i] = follow_path(img, agent_paths[i], all_end[i], num_replan[i])\n",
    "# #             print('next_loc', next_loc, 'num_replan', num_replan[i])\n",
    "# #             print('now agent path', agent_path)\n",
    "#             agent_positions[i] = next_loc\n",
    "#             agent_paths[i] = agent_path\n",
    "#             if agent_positions[i][0] == all_end[i][0] and agent_positions[i][1] == all_end[i][1]:\n",
    "# #                 print('agent', i, 'reach goal')\n",
    "#                 flag_done[i] = current_step\n",
    "#         if 0 not in flag_done:\n",
    "# #             print('finished. cost:', current_step)\n",
    "#             break\n",
    "#         current_step+=1\n",
    "    \n",
    "#     success_count = []\n",
    "#     cost = 0\n",
    "#     makespan = current_step\n",
    "#     for agent_flag in flag_done:\n",
    "#         if agent_flag == 0:\n",
    "#             success_count.append(0)\n",
    "#             cost += expert_makespan*3\n",
    "#         else:\n",
    "#             cost += agent_flag\n",
    "#             success_count.append(1)\n",
    "#     print(flag_done)\n",
    "#     end_time = time.time()\n",
    "#     time_elapsed = end_time - start_time\n",
    "#     time_cost_list.append(time_elapsed)\n",
    "#     flowtime_increase = cost/expert_cost-1\n",
    "#     flowtime_increase_list.append(flowtime_increase)\n",
    "#     individual_success_count += success_count\n",
    "# #     print(time_elapsed, flowtime_increase)\n",
    "# #     print((0 not in success_count), success_count)\n",
    "# #     if (0 in success_count):\n",
    "# #         print(input_data)\n",
    "# #         print(output_data)\n",
    "# #         print(all_paths[success_count.index(0)])\n",
    "#     all_success_count.append((0 not in success_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('{}x{}({})'.format(dim_num[0], dim_num[0], dim_num[1]))\n",
    "# flowtime_increase_array = np.array(flowtime_increase_list)\n",
    "# time_cost_array = np.array(time_cost_list)\n",
    "# all_success_array = np.array(all_success_count)\n",
    "# individual_success_array = np.array(individual_success_count)\n",
    "# print('FT_increase;{};{}'.format(np.mean(flowtime_increase_array), np.std(flowtime_increase_array)))\n",
    "# print('time_cost;{};{}'.format(np.mean(time_cost_array), np.std(time_cost_array)))\n",
    "# print('all_success;{};{}'.format(np.mean(all_success_array), np.std(all_success_array)))\n",
    "# print('individual_success_rate;{};{}'.format(np.mean(individual_success_array), np.std(individual_success_array)))\n",
    "# print('{}x{}({})'.format(dim_num[0], dim_num[0], dim_num[1]),';','{};{};{};{};{};{};{};{}'.format(\n",
    "#         np.mean(flowtime_increase_array), np.std(flowtime_increase_array),\n",
    "#         np.mean(time_cost_array), np.std(time_cost_array),\n",
    "#         np.mean(all_success_array), np.std(all_success_array),\n",
    "#         np.mean(individual_success_array), np.std(individual_success_array),\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG_TIME = int(time.time())\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map20x20_density_p1/10_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 4500\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map28x28_density_p1/20_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map35x35_density_p1/30_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map40x40_density_p1/40_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map45x45_density_p1/50_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map50x50_density_p1/60_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map65x65_density_p1/100_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_TIME = int(time.time())\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map20x20_density_p1/10_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 4500\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map28x28_density_p1/20_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map35x35_density_p1/30_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map40x40_density_p1/40_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map45x45_density_p1/50_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map50x50_density_p1/60_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map65x65_density_p1/100_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_TIME = 1612443878\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/10_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/20_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/30_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/40_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/50_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()\n",
    "\n",
    "DATA_FOLDER = '/media/pc/文档/Dataset/SameMap_diffRobot/map50x50_density_p1/100_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 1000\n",
    "run_in_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/media/pc/文档/Dataset/EffectiveDensity/map65x65_density_p1/100_Agent'\n",
    "# DATA_FOLDER = '/home/pc/experiment_data/60_Agent'\n",
    "DATA_RANGE = [427, 800]\n",
    "DATA_NUM = 5\n",
    "run_in_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_in_pipeline():\n",
    "    data = []\n",
    "    ecbs_data = []\n",
    "    for root, dirs, files in os.walk(os.path.join(DATA_FOLDER, 'input')):\n",
    "        for f in files:\n",
    "            print('loading...', len(data), end='\\r')\n",
    "            if len(data) >= DATA_NUM:\n",
    "                break\n",
    "            IDMAP = f.split('IDMap')[1].split('_')[0]\n",
    "            IDCase = f.split('IDCase')[1].split('.yaml')[0]\n",
    "            IDMAP = int(IDMAP)\n",
    "            IDCase = int(IDCase)\n",
    "            if IDMAP >= DATA_RANGE[0] and IDMAP <= DATA_RANGE[1]:\n",
    "                with open(os.path.join(root, f),'r',encoding='utf-8') as fs:\n",
    "                    cont = fs.read()\n",
    "                    x = yaml.load(cont)\n",
    "\n",
    "                output_name = f.replace('input', 'output').split('.yaml')[0] + '_ECBS.yaml'\n",
    "                output_path = os.path.join(DATA_FOLDER, 'output_ECBS', output_name)\n",
    "                if os.path.exists(output_path):\n",
    "                    with open(output_path ,'r',encoding='utf-8') as fs:\n",
    "                        cont = fs.read()\n",
    "                        y = yaml.load(cont)\n",
    "                    data.append(x)\n",
    "                    ecbs_data.append(y)\n",
    "          \n",
    "    print('finished loading:', len(data))\n",
    "    print(len(ecbs_data))\n",
    "\n",
    "    flowtime_increase_list = []\n",
    "    makespan_list = []\n",
    "    time_cost_list = []\n",
    "    all_success_count = []\n",
    "    individual_success_count = []\n",
    "    num_reachGoal_list = []\n",
    "    dim_num = None\n",
    "\n",
    "    for input_data, output_data in tqdm(zip(data, ecbs_data), total=len(data)):\n",
    "        success_count = []\n",
    "        start_time = time.time()\n",
    "        expert_makespan = output_data['statistics']['makespan']\n",
    "        expert_cost = output_data['statistics']['cost']\n",
    "\n",
    "#         print('===')\n",
    "#         print(input_data)\n",
    "#         print(output_data)\n",
    "        env = np.zeros(input_data['map']['dimensions'])\n",
    "        for obs in input_data['map']['obstacles']:\n",
    "            env[obs[0], obs[1]] = 1\n",
    "        if not dim_num:\n",
    "            dim_num = [input_data['map']['dimensions'][0], len(input_data['agents'])]\n",
    "        all_start = []\n",
    "        all_end = []\n",
    "\n",
    "        agent_paths = []\n",
    "        agent_positions = []\n",
    "        for agent_data in input_data['agents']:\n",
    "            start = agent_data['start']\n",
    "            end = agent_data['goal']\n",
    "            all_start.append(start)\n",
    "            all_end.append(end)\n",
    "            agent_positions.append(start)\n",
    "\n",
    "        # init\n",
    "\n",
    "        for i in range(len(input_data['agents'])):\n",
    "            img = env.copy()\n",
    "    #         print('agent', i, (agent_positions[i][0], agent_positions[i][1]), all_end[i])\n",
    "            for other_agent_pos in [agent_pos for agent_index, \n",
    "                                    agent_pos in enumerate(agent_positions) if agent_index!=i]:\n",
    "                img[other_agent_pos[0], other_agent_pos[1]] = 1\n",
    "    #             print('added as obs', other_agent_pos)\n",
    "            agent_path = AStarSearch(img, (agent_positions[i][0], agent_positions[i][1]), all_end[i])\n",
    "            agent_paths.append(agent_path[1:])\n",
    "\n",
    "        num_replan = [0] * len(input_data['agents'])\n",
    "        flag_done = [0] * len(input_data['agents'])\n",
    "        current_step=1\n",
    "        while current_step < expert_makespan*3:\n",
    "#             print('======roound', current_step)\n",
    "            # start moving\n",
    "            for i in range(len(input_data['agents'])):\n",
    "                if flag_done[i] != 0:\n",
    "#                     print('ignore agent', i, agent_positions[i], 'num_replan', num_replan[i])\n",
    "                    continue\n",
    "                img = env.copy()\n",
    "                # fill in other agents as obstacles\n",
    "                for other_agent_pos in [agent_pos for agent_index, \n",
    "                                        agent_pos in enumerate(agent_positions) if agent_index!=i]:\n",
    "                    img[other_agent_pos[0], other_agent_pos[1]] = 1\n",
    "                img[agent_positions[i][0], agent_positions[i][1]] = 2\n",
    "#                 img[all_end[i][0], all_end[i][1]] = -1\n",
    "#                 print('old agent path', agent_paths[i])\n",
    "                next_loc, agent_path, num_replan[i] = follow_path(img, agent_paths[i], all_end[i], num_replan[i])\n",
    "#                 print('next_loc', next_loc, 'num_replan', num_replan[i])\n",
    "#                 print('now agent path', agent_path)\n",
    "                agent_positions[i] = next_loc\n",
    "                agent_paths[i] = agent_path\n",
    "                if agent_positions[i][0] == all_end[i][0] and agent_positions[i][1] == all_end[i][1]:\n",
    "#                     print('agent', i, 'reach goal')\n",
    "                    flag_done[i] = current_step\n",
    "            if 0 not in flag_done:\n",
    "#                 print('finished. cost:', current_step)\n",
    "                break\n",
    "            current_step+=1\n",
    "\n",
    "        success_count = []\n",
    "        cost = 0\n",
    "        makespan = current_step\n",
    "        makespan_list.append(makespan)\n",
    "        print(flag_done)\n",
    "        print('expert makespan', expert_makespan)\n",
    "        print('expert cost', expert_cost)\n",
    "        print('total in flag done', sum(flag_done))\n",
    "        for agent_flag in flag_done:\n",
    "            if agent_flag == 0:\n",
    "                success_count.append(0)\n",
    "                cost += expert_makespan*3\n",
    "            else:\n",
    "                cost += agent_flag\n",
    "                success_count.append(1)\n",
    "        print('computed cost', cost)\n",
    "        end_time = time.time()\n",
    "        time_elapsed = end_time - start_time\n",
    "        time_cost_list.append(time_elapsed)\n",
    "        flowtime_increase = cost/expert_cost-1\n",
    "        print('FT increase', flowtime_increase)\n",
    "        flowtime_increase_list.append(flowtime_increase)\n",
    "        individual_success_count += success_count\n",
    "        all_success_count.append((0 not in success_count))\n",
    "        \n",
    "        num_reachGoal_list.append(np.count_nonzero(np.array(success_count)))\n",
    "        \n",
    "    print('{}x{}({})'.format(dim_num[0], dim_num[0], dim_num[1]))\n",
    "    flowtime_increase_array = np.array(flowtime_increase_list)\n",
    "    makespan_array = np.array(makespan_list)\n",
    "    time_cost_array = np.array(time_cost_list)\n",
    "    all_success_array = np.array(all_success_count)\n",
    "    individual_success_array = np.array(individual_success_count)\n",
    "    print('FT_increase;{};{}'.format(np.mean(flowtime_increase_array), np.std(flowtime_increase_array)))\n",
    "    print('time_cost;{};{}'.format(np.mean(time_cost_array), np.std(time_cost_array)))\n",
    "    print('all_success;{};{}'.format(np.mean(all_success_array), np.std(all_success_array)))\n",
    "    print('individual_success_rate;{};{}'.format(np.mean(individual_success_array), np.std(individual_success_array)))\n",
    "    \n",
    "    log_time = LOG_TIME\n",
    "    mat_data = {\n",
    "        'rate_ReachGoal':[[np.mean(all_success_array)]],\n",
    "        'num_agents_trained':[[dim_num[1]]],\n",
    "        'num_agents_testing':[[dim_num[1]]],\n",
    "        'map_size_testing':[[dim_num[0], dim_num[0]]],\n",
    "        'map_size_trained': [[dim_num[0], dim_num[0]]],\n",
    "        'map_density_trained': [[0.1]],\n",
    "        'map_density_testing': [[0.1]],\n",
    "        'K':[[0]],\n",
    "        'trained_model_epoch':[[0]],\n",
    "        'log_time':[[log_time]],\n",
    "        'std_deltaMP': [[np.std(makespan_array)]],\n",
    "        'mean_deltaMP':[[np.mean(makespan_array)]],\n",
    "        'list_deltaMP':[[makespan_list]],\n",
    "        'mean_deltaFT':[[np.mean(flowtime_increase_array)]],\n",
    "        'std_deltaFT':[[np.std(flowtime_increase_array)]],\n",
    "        'list_deltaFT': [flowtime_increase_list],\n",
    "        'list_reachGoal':all_success_count,\n",
    "        'list_computationTime':[time_cost_list],\n",
    "        'list_numAgentReachGoal':[num_reachGoal_list],\n",
    "        'action_policy': 'exp_multinorm',\n",
    "        'hidden_state': [[0]],\n",
    "    }\n",
    "    pprint(mat_data)\n",
    "    file_name = 'REPLAN_{}x{}({})_{}_exp_multinorm.mat'.format(dim_num[0], dim_num[0], dim_num[1], log_time)\n",
    "    save_mat(file_name, mat_data)\n",
    "    print('{}x{}({})'.format(dim_num[0], dim_num[0], dim_num[1]),';','{};{};{};{};{};{};{};{}'.format(\n",
    "        np.mean(flowtime_increase_array), np.std(flowtime_increase_array),\n",
    "        np.mean(time_cost_array), np.std(time_cost_array),\n",
    "        np.mean(all_success_array), np.std(all_success_array),\n",
    "        np.mean(individual_success_array), np.std(individual_success_array),\n",
    "    ))\n",
    "    \n",
    "    print('========done========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_ReachGoal = mat_data['rate_ReachGoal'][0][0]\n",
    "mean_deltaFT = mat_data['mean_deltaFT'][0][0]\n",
    "mean_deltaMP = mat_data['mean_deltaMP'][0][0]\n",
    "hidden_state = mat_data['hidden_state'][0][0]\n",
    "trained_model_epoch = mat_data.get('trained_model_epoch', [[-1]])\n",
    "trained_model_epoch = trained_model_epoch[0][0]\n",
    "num_agents_trained = mat_data['num_agents_trained'][0][0]\n",
    "num_agents_testing = mat_data['num_agents_testing'][0][0]\n",
    "map_size_testing = mat_data['map_size_testing'][0][0]\n",
    "K = mat_data['K'][0][0]\n",
    "cleaned_data = {\n",
    "    'filename': file,\n",
    "    'type': data_type,\n",
    "    'action_policy': action_policy,\n",
    "    'map_size_trained': mat_data['map_size_trained'][0],\n",
    "    'map_density_trained': mat_data['map_density_trained'][0][0],\n",
    "    'num_agents_trained': mat_data['num_agents_trained'][0][0],\n",
    "    'map_size_testing': mat_data['map_size_testing'][0],\n",
    "    'map_size_testing_int': mat_data['map_size_testing'][0][0],\n",
    "    'map_density_testing': mat_data['map_density_testing'][0][0],\n",
    "    'num_agents_testing': mat_data['num_agents_testing'][0][0],\n",
    "    'log_time': log_time,\n",
    "    'K': K,\n",
    "    # 'data_set' : mat_data['data_set'][0][0],\n",
    "    'hidden_state': hidden_state,\n",
    "    'rate_ReachGoal': rate_ReachGoal,\n",
    "    'list_reachGoal': mat_data.get('list_reachGoal', None),\n",
    "    'list_computationTime': mat_data.get('list_computationTime', None),\n",
    "    'mean_deltaFT': mean_deltaFT,\n",
    "    'std_deltaMP': mat_data['std_deltaMP'][0][0],\n",
    "    'mean_deltaMP': mean_deltaMP,\n",
    "    'std_deltaFT': mat_data['std_deltaFT'][0][0],\n",
    "    'trained_model_epoch': trained_model_epoch,\n",
    "    'list_deltaFT': mat_data['list_deltaFT'][0],\n",
    "    # 'list_FT_predict': mat_data['list_FT_predict'][0],\n",
    "    # 'list_FT_target': mat_data['list_FT_target'][0],\n",
    "    #\n",
    "    # 'list_reachGoal': mat_data['list_reachGoal'][0],\n",
    "    'list_numAgentReachGoal': mat_data['list_numAgentReachGoal'][0],\n",
    "    'hist_numAgentReachGoal': mat_data['hist_numAgentReachGoal'][0],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
